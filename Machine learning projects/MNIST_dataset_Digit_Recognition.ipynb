{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPz3T6g2pYuGtN0KaZVj9F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishekmishra-bareilly/Machine-learning/blob/main/MNIST_dataset_Digit_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Digit Recognition on MNIST dataset"
      ],
      "metadata": {
        "id": "iDHGEcSiKV1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**fetching dataset**"
      ],
      "metadata": {
        "id": "NJflsD1CLb1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LVMBEKDfLk9_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784')"
      ],
      "metadata": {
        "id": "6g63wtsJMrwd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In this data we have data and target\n",
        "x, y = mnist['data'], mnist['target']"
      ],
      "metadata": {
        "id": "qO0eQcNEP47e"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let see some data\n",
        "some_digit = x.to_numpy()[36001]\n",
        "# Reshape the data\n",
        "some_digit_image = some_digit.reshape(28,28)\n",
        "\n",
        "# print the data in 36001 row\n",
        "plt.imshow(some_digit_image, cmap=matplotlib.cm.binary, interpolation='nearest')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "9lnvJ-ngQgEj",
        "outputId": "e7939ea2-073a-4cd8-e799-6db95175931a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split train the data and the test the data**"
      ],
      "metadata": {
        "id": "KIqiNBAOTH4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using train_test_split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test = train_test_split(x, test_size = 0.2, random_state=42)\n",
        "print(f'Row in x train set: {len(x_train)} \\n Rows in x_test set: {len(x_test)}\\n')\n",
        "\n",
        "y_train, y_test = train_test_split(y, test_size = 0.2, random_state=42)\n",
        "print(f'Row in y train set: {len(y_train)} \\n Rows in y_test set: {len(y_test)}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bteSWhUtdkBs",
        "outputId": "3bf50f3f-80d9-4f84-ba3f-9cedc84842c2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row in x train set: 56000 \n",
            " Rows in x_test set: 14000\n",
            "\n",
            "Row in y train set: 56000 \n",
            " Rows in y_test set: 14000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model**"
      ],
      "metadata": {
        "id": "Y2ah9vcfgpHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a 2-detector\n",
        "y_train = y_train.astype(np.int8)\n",
        "y_test = y_test.astype(np.int8)"
      ],
      "metadata": {
        "id": "AGghb-3Mehh0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now convert the data in bllonform\n",
        "y_train_2 = (y_train == 2)\n",
        "y_test_2 = (y_test == 2)"
      ],
      "metadata": {
        "id": "BmDaESycfyh8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train a logistic regression classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression()\n",
        "clf.fit(x_train, y_train_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HADfDrSgvHN",
        "outputId": "e90b885b-4196-41c5-bcef-6afd5675369d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement this model on a single row**"
      ],
      "metadata": {
        "id": "CpFyfmI4oiMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the data of row no.36001\n",
        "some_digit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZg4T90riFdT",
        "outputId": "f05b4901-8ba6-46b5-827a-3b5eb20cec7b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,  19.,  29., 128., 255., 253., 253., 253., 192.,\n",
              "        97.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  57., 187., 252.,\n",
              "       252., 253., 252., 252., 252., 253., 196.,  63.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0., 216., 233., 168., 168., 106.,  56.,  56., 106.,\n",
              "       216., 252., 168.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  79., 109.,\n",
              "         0.,   0.,   0.,   0.,   0.,  51., 241., 252., 243.,  25.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        26., 254., 247., 150.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0., 225., 253., 196.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "       104., 246., 244.,  81.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0., 101., 246., 252., 125.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  92.,\n",
              "       216., 244., 125.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,  19.,  57., 253., 240., 130.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  47., 240.,\n",
              "       253., 158.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0., 114., 113., 210., 252., 253., 133.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,  32., 141., 241., 254., 253., 253.,\n",
              "       253., 254., 253., 216.,  41.,  13.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  95.,\n",
              "       187., 252., 252., 253., 240., 196., 145., 203., 252., 252., 252.,\n",
              "       207.,  94.,  38.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0., 126., 229., 252., 252., 252., 253., 109.,\n",
              "         0.,   0.,   7., 130., 196., 252., 253., 252., 196.,  10.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  26., 200., 249.,\n",
              "       178., 178., 252., 252., 128.,   9.,   0.,   0.,   0.,   0.,  10.,\n",
              "        28., 140., 139., 103.,   3.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,  70., 253., 241., 154., 253., 244.,  75.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   7., 187., 252.,\n",
              "       215., 253., 189.,  56.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,  29., 252., 252., 252., 194.,  19.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  66., 215.,\n",
              "       252., 102.,  13.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "         0.,   0.,   0.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# les perform an example\n",
        "example = clf.predict([some_digit])\n",
        "print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4gmVWS8jO_Y",
        "outputId": "debb3c8c-95a6-4ea1-a475-a0f1c5ad7613"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross valilation**"
      ],
      "metadata": {
        "id": "jsKSt9G8oz-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross valilation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "a = cross_val_score(clf, x_train, y_train_2, cv = 3, scoring='accuracy')\n",
        "print(a.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GVBdbdNkA_y",
        "outputId": "59867006-6a93-4426-dead-8dd10558763b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9769999830845193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**so we got mean 0.9769999830845193**"
      ],
      "metadata": {
        "id": "ov-7wgDgnwmz"
      }
    }
  ]
}
